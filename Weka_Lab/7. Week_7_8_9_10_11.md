


![cost curve fn1](https://github.com/00Pratik-Biswas00/College_Sixth_Semester_Labs/assets/114896796/867b7084-e070-44fb-bddb-0ec6d71ede75)



![cost curve fn5](https://github.com/00Pratik-Biswas00/College_Sixth_Semester_Labs/assets/114896796/26da2a9e-cd39-459e-961a-ae4836914109)



![roc curve](https://github.com/00Pratik-Biswas00/College_Sixth_Semester_Labs/assets/114896796/b773c57b-baa4-451f-b4e2-20226767592f)



![Screenshot (5)](https://github.com/00Pratik-Biswas00/College_Sixth_Semester_Labs/assets/114896796/6a26e8ad-eab2-4a39-9174-75d3402454e8)


WEEK-7:

1. Check to see if the data shows a bias against “foreign workers” or “personal-status”. Did removing these attributes have any significantly effect? Discuss.

After choosing a classifier to evaluate the credit-g dataset with and without the attributes "foreign workers" and "personal-status", we note down the performance metrics such as precision, accuracy, recall, and F1-score, between the two datasets.
We see that after removing the attributes "foreign workers" and "personal-status" it does not have any significant effect on the model's performance. As there is no significant difference in performance metrics between the two datasets, it indicates that these attributes were not influential in the model's predictions, suggesting no evident bias.


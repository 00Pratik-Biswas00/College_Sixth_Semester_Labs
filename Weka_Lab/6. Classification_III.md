# WEEK-6: Use other classifiers on German Credit Data-Credit risk assessment problem


#### [1. One approach for solving the problem encountered in the previous question (Week 5) is using cross-validation. Describe what is cross-validation briefly. Train a decision tree again using cross-validation and report your results. Does accuracy increase/decrease? Why?](#section-1)

#### [2. Define a baseline accuracy using Zero-R classifier and compare the results with the results of J48 classifier; describe your findings.](#section-2)

#### [3. Build a classifier model for the credit risk assessment problem using other classifiers, such as Random Forest, Logistic Regression, Support Vector Machine, etc. Which classifier does the best? Substantiate your answer with ROC and AUC results.](#section-3)


## 1. One approach for solving the problem encountered in the previous question (Week 5) is using cross-validation. Describe what is cross-validation briefly. Train a decision tree again using cross-validation and report your results. Does accuracy increase/decrease? Why?<a name="section-1"></a>

#### Cross-validation:

It is a technique used in machine learning to assess the performance and generalization ability of a model. It involves partitioning the dataset into multiple subsets (or folds), training the model on several of these subsets, and then evaluating the model on the remaining subset(s). This process is repeated multiple times, with each subset used as both a training set and a validation set. The key idea behind cross-validation is to obtain a more robust estimate of the model's performance by averaging results across multiple data splits.

#### Report:

![DT_crossValidation](https://github.com/00Pratik-Biswas00/College_Sixth_Semester_Labs/assets/114896796/17bc72c7-174c-4325-8243-7744c73db45f)

#### Does accuracy increase/decrease? Why?

The accuracy decreases. Training a decision tree using cross-validation can have varying effects on accuracy compared to training a decision tree using a single train-test split, depending on the dataset and the specific circumstances. Here are some points to consider:

1. Increased Reliability: Cross-validation provides a more reliable estimate of the model's performance.

2. Potential Improvement in Generalization: Cross-validation helps to ensure that the model generalizes well to unseen data. This may lead to better performance on new, unseen data.

3. Better Hyperparameter Tuning: This can help in finding the optimal hyperparameters for the decision tree model, potentially leading to improved accuracy.

4. Increased Computational Cost: Cross-validation involves training the model multiple times, which can be computationally expensive.

5. Risk of Overfitting: While cross-validation can help in assessing the generalization performance of the model, it does not eliminate the risk of overfitting entirely.

The actual impact on accuracy compared to a normal decision tree algorithm depends on various factors such as the dataset, model complexity, and the specific implementation of cross-validation.

## 2. Define a baseline accuracy using Zero-R classifier and compare the results with the results of J48 classifier; describe your findings.<a name="section-2"></a>

#### J48

![DT_J48](https://github.com/00Pratik-Biswas00/College_Sixth_Semester_Labs/assets/114896796/0752b05b-19b4-40bc-b72b-cb56e744f727)


#### Zero-R

![DT_zeroR](https://github.com/00Pratik-Biswas00/College_Sixth_Semester_Labs/assets/114896796/a1426d9d-ce8a-4e95-ad95-70cb58ac668a)

#### Findings and Interpretation:

The J48 (C4.5 Decision Tree) Classifier is a more complex model that learns from the data and attempts to make predictions based on features.
Compare the accuracy of the J48 classifier (accuracy_j48) with the accuracy of the Zero-R classifier (accuracy_zero_r). The J48 classifier's accuracy should ideally be significantly higher than the Zero-R classifier's accuracy, indicating that the J48 model is learning meaningful patterns from the data.
If the J48 classifier's accuracy is not much higher than the Zero-R classifier's accuracy, it suggests that the decision tree model may not be effectively capturing the underlying patterns in the data or is overfitting.

## 3. Build a classifier model for the credit risk assessment problem using other classifiers, such as Random Forest, Logistic Regression, Support Vector Machine, etc. Which classifier does the best? Substantiate your answer with ROC and AUC results. <a name="section-3"></a>

#### SVM:

![svm](https://github.com/00Pratik-Biswas00/College_Sixth_Semester_Labs/assets/114896796/6cac765e-de99-4101-a82c-a4310acafcc6)

#### Logistic Regression:

![logistic_regression](https://github.com/00Pratik-Biswas00/College_Sixth_Semester_Labs/assets/114896796/8879efe7-bc85-4d12-8abf-796313fc9219)

#### Random Forest:

![random_forest](https://github.com/00Pratik-Biswas00/College_Sixth_Semester_Labs/assets/114896796/a7aed3b6-7f31-400e-a1db-3399ecb51ca0)

We obtain a plot with ROC curves for Random Forest (AUC = 1.00), Logistic Regression (AUC = 0.834), and Support Vector Machine (AUC = 0.710). In this case, the Random Forest classifier with the highest AUC value of 0.85 performs the best among the three classifiers for the credit risk assessment task.



